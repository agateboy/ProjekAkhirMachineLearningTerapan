# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y92gSQ-MkAPHLDeIMPZroNdqlCgB_ZRp

# 1. IMPORT LIBRARY

Pada tahap ini dilakukan import library python yang dibutuhkan untuk pengembangan proyek
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

"""# 2. DATA LOADING

Pada tahap ini, dataset diambil dari Google Drive.
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/drive')

kenyamanan_prediction = pd.read_csv('/content/drive/MyDrive/kenyamanan.csv')
kenyamanan_prediction.head()

"""# 3. EDA (Exploratory Data Analysis)

Pada proses ini dilakukan pengecekan terhadap data kosong (Null), dan pengecekan tipe variabel dataset.
"""

kenyamanan_prediction.info()

kenyamanan_prediction.describe()

kenyamanan_prediction.isnull().sum()

(kenyamanan_prediction == 0).sum()

kenyamanan_prediction.describe()

"""# 4. VISUALISASI DATA

Pengecekan outliers untuk menangani data yang jauh dari data utama sehingga tidak membuat noise saat dilakukan training model.
"""

fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=kenyamanan_prediction.Temperature)
sns.boxplot(ax=axes[0, 1], x=kenyamanan_prediction.Humidity)
sns.boxplot(ax=axes[0, 2], x=kenyamanan_prediction.Noise)

sns.boxplot(ax=axes[1, 0], x=kenyamanan_prediction.Light)
sns.boxplot(ax=axes[1, 1], x=kenyamanan_prediction.Oxygen)
sns.boxplot(ax=axes[1, 2], x=kenyamanan_prediction.Comfort)

"""IQR"""

Q1 = kenyamanan_prediction.quantile(0.25)
Q3 = kenyamanan_prediction.quantile(0.75)
IQR = Q3 - Q1
kenyamanan_prediction = kenyamanan_prediction[~((kenyamanan_prediction < (Q1 - 1.5 * IQR)) | (kenyamanan_prediction > (Q3 + 1.5 * IQR))).any(axis=1)]
kenyamanan_prediction

"""Menggunakan metode IQR untuk menormalisasikan dan membersihkan outliers sebelum disiapkan untuk menjadi model machine learning."""

fig, axes = plt.subplots(2, 3, figsize=(14, 7))

sns.boxplot(ax=axes[0, 0], x=kenyamanan_prediction.Temperature)
sns.boxplot(ax=axes[0, 1], x=kenyamanan_prediction.Humidity)
sns.boxplot(ax=axes[0, 2], x=kenyamanan_prediction.Noise)

sns.boxplot(ax=axes[1, 0], x=kenyamanan_prediction.Light)
sns.boxplot(ax=axes[1, 1], x=kenyamanan_prediction.Oxygen)
sns.boxplot(ax=axes[1, 2], x=kenyamanan_prediction.Comfort)

"""### Univariate Analysis (Numerical Features)

Univariate: Histogram, boxplot, dan deskripsi statistik digunakan untuk menganalisis distribusi masing-masing variabel.
"""

kenyamanan_prediction.hist(bins = 50, figsize=(14, 7))
plt.show

"""### Multivariate Analysis

Multivariate: Korelasi dan scatterplot digunakan untuk melihat hubungan antar fitur dengan target (Comfort).
"""

sns.pairplot(kenyamanan_prediction, diag_kind='kde')

"""Correlation Matrix"""

plt.figure(figsize=(14, 8))
correlation_matrix = kenyamanan_prediction.corr().round(2)
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix', size = 14)

"""- Temperature dan Humidity memiliki korelasi negatif sedang (-0.57), menunjukkan bahwa ketika suhu naik, kelembaban cenderung menurun.

- Oxygen memiliki korelasi positif moderat terhadap Comfort (0.44), mengindikasikan kadar oksigen tinggi mungkin meningkatkan kenyamanan kerja.

- Noise dan Light memiliki korelasi rendah terhadap Comfort, kemungkinan kontribusinya kecil secara langsung terhadap skor kenyamanan.

- Korelasi antar fitur lainnya relatif rendah, sehingga multikolinearitas tidak menjadi isu besar dalam pemodelan.

# 5. DATA PREPARATION

Pada tahap ini mempersiapkan data yang akan digunakan untuk Model Development, dengan pembagian 80% untuk pelatihan (Training) dan 20% untuk pengujian (Testing)
"""

from sklearn.model_selection import train_test_split
X = kenyamanan_prediction.drop('Comfort', axis=1)
y = kenyamanan_prediction['Comfort']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f'Total seluruh sampel dalam dataset: {len(X)}')
print(f'Total sampel dalam train dataset: {len(X_train)}')
print(f'Total samepl dalam test dataset: {len(X_test)}')

"""Standarisasi"""

numerical_features = ['Temperature', 'Humidity', 'Noise', 'Light', 'Oxygen']
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train[numerical_features])
X_test[numerical_features] = scaler.transform(X_test[numerical_features])
X_train[numerical_features].head()

"""# 6. MODEL DEVELOPMENT

### KNN

Data dilatih dengan model pertama yaitu `KNN (K-Nearest Neighbors)` dengan nilai k tetangga terdekat adalah 5.
"""

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print("KNN Accuracy:", accuracy_score(y_test, y_pred_knn))
print("KNN Classification Report:\n", classification_report(y_test, y_pred_knn))

"""### Gradient Boosting

Setelah itu, model dilatih menggunakan `Gradient Boosting` dengan jumlah pohon keputusan yang dibangun adalah 100.
"""

from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)
print("Gradient Boosting Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Gradient Boosting Classification Report:\n", classification_report(y_test, y_pred_gb))

"""### RF

Model selanjutnya dilatih menggunakan metode `Random Forest` dengan menentukan nilai `n_estimators` adalah 100 yang menggabungkan banyak pohon untuk meningkatkan akurasi.
"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10, n_jobs=-1)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Random Forest Classification Report:\n", classification_report(y_test, y_pred_rf))

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

cm_knn = confusion_matrix(y_test, y_pred_knn)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', xticklabels=knn.classes_, yticklabels=knn.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - KNN')
plt.show()

cm_gb = confusion_matrix(y_test, y_pred_gb)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_gb, annot=True, fmt='d', cmap='Blues', xticklabels=gb.classes_, yticklabels=gb.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Gradient Boosting')
plt.show()

cm_rf = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Random Forest')
plt.show()

"""# 7. EVALUASI MODEL"""

def plot_classification_report(report, title):
    report_dict = classification_report(report[0], report[1], output_dict=True)
    df = pd.DataFrame(report_dict).transpose()
    df = df.iloc[:-1, :-1]
    df = df.astype(float)
    df.plot(kind='bar', figsize=(10, 6))
    plt.title(title)
    plt.ylabel('Score')
    plt.ylim([0.0, 1.1])
    plt.xticks(rotation=0)
    plt.legend(loc='best')
    plt.tight_layout()
    plt.show()

knn_report_data = (y_test, y_pred_knn)
svm_report_data = (y_test, y_pred_gb)
rf_report_data = (y_test, y_pred_rf)

plot_classification_report(knn_report_data, 'KNN Classification Report')
plot_classification_report(svm_report_data, 'Gradient Boosting Classification Report')
plot_classification_report(rf_report_data, 'Random Forest Classification Report')

import matplotlib.pyplot as plt
plt.figure(figsize=(8, 6))
model_names = ['KNN', 'Gradient Boosting', 'Random Forest']
accuracies = [
    accuracy_score(y_test, y_pred_knn),
    accuracy_score(y_test, y_pred_gb),
    accuracy_score(y_test, y_pred_rf)
]

plt.bar(model_names, accuracies, color=['blue', 'green', 'red'])
plt.ylabel('Accuracy')
plt.title('Accuracy of Three Models')
plt.ylim([0.0, 1.1])
plt.show()

"""Berdasarkan hasil training, didapat metode pelatihan model `Random Forest` memiliki accuracy score tertinggi yaitu `95,17%` sehingga model dari `Random Forest` akan dipilih sebagai sistem prediksi kenyamanan."""